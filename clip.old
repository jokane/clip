import glob
import io
import zipfile

import pdf2image
import scipy.signal



def to_monochrome(clip):
    """ Convert a clip's video to monochrome. """
    def mono(frame):
        return cv2.cvtColor(cv2.cvtColor(frame, cv2.COLOR_BGRA2GRAY), cv2.COLOR_GRAY2BGRA)

    return filter_frames(
      clip=clip,
      func=mono,
      name='to_monochrome',
      size='same'
    )

class resample(MutatorClip):
    """ Change some combination of the frame rate, sample rate, and length. """
    def __init__(self, clip, frame_rate=None, sample_rate=None, length=None):

        super().__init__(clip)

        if frame_rate is not None:
            require_float(frame_rate, "frame rate")
            require_positive(frame_rate, "frame rate")
        else:
            frame_rate = self.clip.frame_rate()

        if sample_rate is not None:
            require_float(sample_rate, "sample rate")
            require_positive(sample_rate, "sample rate")
        else:
            sample_rate = self.clip.sample_rate()

        if length is not None:
            require_float(length, "length")
            require_positive(length, "length")
        else:
            length = self.clip.length()

        self.metrics = Metrics(src=self.clip.metrics,
                               frame_rate=frame_rate,
                               sample_rate=sample_rate,
                               length=length)

    def new_index(self, index):
        """ Return the index in the original clip to be used at the given index
        of the present clip. """
        # print()
        # print("index:", index)
        # print("self.length():", self.length())
        # print("self.num_frames():", self.num_frames())
        assert index < self.num_frames()
        seconds_here = self.length() * index / self.num_frames()
        # print("seconds_here:", seconds_here)
        assert seconds_here <= self.length()
        seconds_there = seconds_here * self.clip.length() / self.length()
        # print("seconds_there:", seconds_there)
        # print("self.clip.frame_rate():", self.clip.frame_rate())
        assert seconds_there <= self.clip.length()
        index_there = int(seconds_there * self.clip.frame_rate())
        # print("index_there:", index_there)
        # print("correct time range for index_there:",
        #      index_there/self.clip.frame_rate(), (index_there+1)/self.clip.frame_rate())
        # print("self.clip.num_frames():", self.clip.num_frames())
        assert index_there < self.clip.num_frames(), f'{index_there}, {self.clip.num_frames()}'
        return index_there

    def frame_signature(self, index):
        return self.clip.frame_signature(self.new_index(index))

    def get_frame(self, index):
        return self.clip.get_frame(self.new_index(index))

    def get_samples(self):
        data = self.clip.get_samples()
        if self.clip.sample_rate() != self.sample_rate() or self.clip.length() != self.length():
            data = scipy.signal.resample(data, self.num_samples())
        return data

def slice_out(clip, start, end):
    """ Remove the part between the given endponts. """
    require_clip(clip, "clip")
    require_float(start, "start time")
    require_non_negative(start, "start time")
    require_float(end, "end time")
    require_positive(end, "end time")
    require_less(start, end, "start time", "end time")
    require_less_equal(end, clip.length(), "end time", "clip length")

    return chain(slice_clip(clip, 0, start),
                 slice_clip(clip, end, clip.length()))


def letterbox(clip, width, height):
    """ Fix the clip within given dimensions, adding black bands on the
    top/bottom or left/right if needed. """
    require_clip(clip, "clip")
    require_int(width, "width")
    require_positive(width, "width")
    require_int(height, "height")
    require_positive(height, "height")

    scaled = scale_to_fit(clip, width, height)

    position=[int((width-scaled.width())/2),
              int((height-scaled.height())/2)]

    return composite(Element(clip=scaled,
                             start_time=0,
                             position=position,
                             video_mode=VideoMode.REPLACE,
                             audio_mode=AudioMode.REPLACE),
                      width=width,
                      height=height)


class repeat_frame(VideoClip):
    """Shows the same frame, from another clip, over and over."""
    def __init__(self, clip, when, length):
        super().__init__()
        require_clip(clip, "clip")
        require_float(when, "time")
        require_non_negative(when, "time")
        require_less_equal(when, clip.length(), "time", "clip length")
        require_float(length, "length")
        require_positive(length, "length")

        self.metrics = Metrics(src=clip.metrics,
                               length=length)
        self.clip = clip
        self.frame_index = int(when * self.frame_rate())

        # Special case for repeating at/near the end of the clip: Because of
        # how time is scaled, we might end up asking for one frame beyond the
        # end.
        if self.frame_index == self.clip.num_frames():
            self.frame_index -= 1

        assert self.frame_index < self.clip.num_frames()

    def frame_signature(self, index):
        assert index < self.num_frames()
        return self.clip.frame_signature(self.frame_index)

    def get_frame(self, index):
        return self.clip.get_frame(self.frame_index)

def hold_at_end(clip, target_length):
    """Extend a clip by repeating its last frame, to fill a target length."""
    require_clip(clip, "clip")
    require_float(target_length, "target length")
    require_positive(target_length, "target length")

    # Here the repeat_frame almost certainly goes beyond target length, and
    # we force the final product to have the right length directly.  This
    # prevents getting a blank frame at end in some cases.
    return chain(clip,
                 repeat_frame(clip, clip.length(), target_length),
                 length=target_length)


class image_glob(VideoClip):
    """Video from a collection of identically-sized image files that match
    a unix-style pattern, at a given frame rate."""
    def __init__(self, pattern, frame_rate):
        super().__init__()

        require_string(pattern, "pattern")
        require_float(frame_rate, "frame rate")
        require_positive(frame_rate, "frame rate")

        self.pattern = pattern

        self.filenames = sorted(glob.glob(pattern))
        if len(self.filenames) == 0:
            raise FileNotFoundError(f'No files matched pattern: {pattern}')

        # Get full pathnames, in case the current directory changes.
        self.filenames = list(map(lambda x: os.path.join(os.getcwd(), x), self.filenames))

        sample_frame = cv2.imread(self.filenames[0])
        assert sample_frame is not None

        self.metrics = Metrics(src=Clip.default_metrics,
                               width=sample_frame.shape[1],
                               height=sample_frame.shape[0],
                               frame_rate = frame_rate,
                               length = len(self.filenames)/frame_rate)

    def frame_signature(self, index):
        assert index<self.num_frames()
        return self.filenames[index]

    def get_frame(self, index):
        return read_image(self.filenames[index])

class zip_file(VideoClip):
    """ A video clip from images stored in a zip file."""

    def __init__(self, fname, frame_rate):
        super().__init__()

        require_string(fname, "file name")
        require_float(frame_rate, "frame rate")
        require_positive(frame_rate, "frame rate")

        if not os.path.isfile(fname):
            raise FileNotFoundError(f'Trying to open {fname}, which does not exist.')

        self.fname = fname
        self.zf = zipfile.ZipFile(fname, 'r') #pylint: disable=consider-using-with

        image_formats = ['tga', 'jpg', 'jpeg', 'png'] # (Note: Many others could be added here.)
        pattern = ".(" + "|".join(image_formats) + ")$"

        info_list = self.zf.infolist()
        info_list = filter(lambda x: re.search(pattern, x.filename), info_list)
        info_list = sorted(info_list, key=lambda x: x.filename)
        self.info_list = info_list

        self.frame_rate_ = frame_rate

        sample_frame = self.get_frame(0)

        self.metrics = Metrics(src = Clip.default_metrics,
                               width=sample_frame.shape[1],
                               height=sample_frame.shape[0],
                               frame_rate = frame_rate,
                               length = len(self.info_list)/frame_rate)

    def frame_signature(self, index):
        return ['zip file member', self.fname, self.info_list[index].filename]

    def get_frame(self, index):
        data = self.zf.read(self.info_list[index])
        pil_image = Image.open(io.BytesIO(data)).convert('RGBA')
        frame = np.array(pil_image)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGRA)
        return frame

def to_default_metrics(clip):
    """Adjust a clip so that its metrics match the default metrics: Scale video
    and resample to match frame rate and sample rate.  Useful if assorted clips
    from various sources will be chained together."""

    require_clip(clip, "clip")

    dm = Clip.default_metrics

    # Video dimensions.
    if clip.width() != dm.width or clip.height() != dm.height:
        clip = letterbox(clip, dm.width, dm.height)

    # Frame rate and sample rate.
    if (clip.frame_rate() != dm.frame_rate
          or clip.sample_rate() != dm.sample_rate):
        clip = resample(clip,
                        frame_rate=dm.frame_rate,
                        sample_rate=dm.sample_rate)

    # Number of audio channels.
    nc_before = clip.num_channels()
    nc_after = dm.num_channels
    if nc_before == nc_after:
        pass
    elif nc_before == 2 and nc_after == 1:
        clip = stereo_to_mono(clip)
    elif nc_before == 1 and nc_after == 2:
        clip = mono_to_stereo(clip)
    else:
        raise NotImplementedError(f"Don't know how to convert from {nc_before}"
                                  f"channels to {nc_after}.")

    return clip

def timewarp(clip, factor):
    """ Speed up a clip by the given factor. """
    require_clip(clip, "clip")
    require_float(factor, "factor")
    require_positive(factor, "factor")

    return resample(clip, length=clip.length()/factor)

def pdf_page(pdf_file, page_num, frame_rate, length, **kwargs):
    """A silent video constructed from a single page of a PDF."""
    require_string(pdf_file, "file name")
    require_int(page_num, "page number")
    require_positive(page_num, "page number")
    require_float(frame_rate, "frame rate")
    require_positive(frame_rate, "frame rate")
    require_float(length, "length")
    require_positive(length, "length")

    # Hash the file.  We'll use this in the name of the static_frame below, so
    # that things are re-generated correctly when the PDF changes.
    pdf_hash = sha256sum_file(pdf_file)

    # Get an image of the PDF.
    images = pdf2image.convert_from_path(pdf_file,
                                         first_page=page_num,
                                         last_page=page_num,
                                         **kwargs)
    image = images[0].convert('RGBA')
    frame = np.array(image)
    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGRA)

    # Sometimes we get, for reasons not adequately understood, an image that is
    # not the correct size, off by one in the width.  Fix it.
    if 'size' in kwargs:
        w = kwargs['size'][0]
        h = kwargs['size'][1]
        if h != frame.shape[0] or w != frame.shape[1]:
            frame = frame[0:h,0:w]  # pragma: no cover

    # Form a clip that shows this image repeatedly.
    return static_frame(frame,
                        frame_name=f'{pdf_file} ({pdf_hash}), page {page_num} {kwargs}',
                        frame_rate=frame_rate,
                        length=length)

class spin(MutatorClip):
    """ Rotate the contents of a clip about the center, a given number of
    times. Rotational velocity is computed to complete the requested rotations
    within the length of the original clip."""
    def __init__(self, clip, total_rotations):
        super().__init__(clip)

        require_float(total_rotations, "total rotations")
        require_non_negative(total_rotations, "total rotations")

        # Leave enough space to show the full undrlying clip at every
        # orientation.
        self.radius = math.ceil(math.sqrt(clip.width()**2 + clip.height()**2))

        self.metrics = Metrics(src=clip.metrics,
                               width=self.radius,
                               height=self.radius)

        # Figure out how much to rotate in each frame.
        rotations_per_second = total_rotations / clip.length()
        rotations_per_frame = rotations_per_second / clip.frame_rate()
        self.degrees_per_frame = 360 * rotations_per_frame

    def frame_signature(self, index):
        assert index < self.num_frames()
        sig = self.clip.frame_signature(index)
        degrees = self.degrees_per_frame * index
        return [f'rotated by {degrees}', sig]

    def get_frame(self, index):
        frame = np.zeros([self.radius, self.radius, 4], np.uint8)
        original_frame = self.clip.get_frame(index)

        a = (frame.shape[0] - original_frame.shape[0])
        b = (frame.shape[1] - original_frame.shape[1])

        frame[
            int(a/2):int(a/2)+original_frame.shape[0],
            int(b/2):int(b/2)+original_frame.shape[1],
            :
        ] = original_frame

        degrees = self.degrees_per_frame * index

        # https://stackoverflow.com/questions/9041681/opencv-python-rotate-image-by-x-degrees-around-specific-point
        image_center = tuple(np.array(frame.shape[1::-1]) / 2)
        rot_mat = cv2.getRotationMatrix2D(image_center, degrees, 1.0)
        rotated_frame = cv2.warpAffine(frame,
                                       rot_mat,
                                       frame.shape[1::-1],
                                       flags=cv2.INTER_NEAREST,
                                       borderMode=cv2.BORDER_CONSTANT,
                                       borderValue=[0,0,0,0])
        # Using INTER_NEAREST here instead of INTER_LINEAR has two effects:
        # 1. It prevents an artifical "border" from appearing when INTER_LINEAR
        # blends "real" pixels with the background zeros around the edge of the
        # real image.  This is sort of built in if we rotate when there are
        # "real" pixels close to [0,0,0,0] background pixels.
        # 2. It gives straight lines a jagged looks.
        #
        # Perhaps a better version might someday get the best of both worlds by
        # embedding the real image in a larger canvas (filled somehow with the
        # right color -- perhaps by grabbing from the boundary of the real
        # image?), rotating that larger image with INTER_LINEAR (creating an
        # ugly by distant border), and then cropping back to the radius x
        # radius size that we need.

        return rotated_frame

class Align(Enum):
    """ When stacking clips, how should each be placed? """
    CENTER = 1
    LEFT = 2
    TOP = 3
    START = 4
    RIGHT = 5
    BOTTOM = 6
    END = 7

def stack_clips(*args, align, min_dim=0, vert, name):
    """ Arrange a series of clips in a stack, either vertically or
    horizontally.  Probably use vstack or hstack to call this. """

    # Flatten things out, in case the inputs were wrapped in a list.
    clips = flatten_args(args)

    # Compute the width or height.  Do this first so we can maybe center things
    # below.
    dim = min_dim
    for clip in clips:
        if isinstance(clip, Clip):
            clip_dim = clip.width() if vert else clip.height()
            dim = max(dim, clip_dim)
        elif is_int(clip):
            pass
        else:
            raise TypeError(f"In {name}, got a {type(clip)} instead of Clip or int.")

    # Sanity check the alignment.
    if vert:
        valid_aligns = [Align.LEFT, Align.RIGHT, Align.CENTER]
    else:
        valid_aligns = [Align.TOP, Align.BOTTOM, Align.CENTER]

    if align not in valid_aligns:
        raise NotImplementedError(f"Don't know how to align {align} in {name}.")


    # Place each clip in the composite in the correct place.

    a = 0  # The coordinate that we compute each time based on align.
    b = 0  # The coordinate that moves steady forward.

    elements = []

    for clip in clips:
        if isinstance(clip, Clip):
            clip_dim = clip.width() if vert else clip.height()

            if align in [Align.LEFT, Align.TOP]:
                a = 0
            elif align==Align.CENTER:
                a = int((dim - clip_dim)/2)
            else: # align in [Align.RIGHT, Align.BOTTOM]
                a = dim - clip_dim

            elements.append(Element(clip=clip,
                                    start_time=0,
                                    position=[a, b] if vert else [b, a]))

            b += clip.height() if vert else clip.width()
        else: # must be an int, as checked above
            b += clip

    if vert:
        return composite(elements, width=dim, height=b)
    else:
        return composite(elements, height=dim, width=b)

def vstack(*args, align=Align.CENTER, min_width=0):
    """ Arrange a series of clips in a vertical stack. """
    return stack_clips(args, align=align, min_dim=min_width, vert=True, name='vstack')

def hstack(*args, align=Align.CENTER, min_height=0):
    """ Arrange a series of clips in a horizontal row. """
    return stack_clips(args, align=align, min_dim=min_height, vert=False, name='hstack')

def background(clip, bg_color):
    """ Blend a clip onto a same-sized background of the given color. """
    require_clip(clip, 'clip')
    require_color(bg_color, 'background color')

    return composite(Element(solid(bg_color,
                                   clip.width(),
                                   clip.height(),
                                   clip.frame_rate(),
                                   clip.length()),
                             0,
                             (0,0)),
                      Element(clip,
                              0,
                              (0,0),
                              video_mode=VideoMode.BLEND))


def superimpose_center(under_clip, over_clip, start_time, audio_mode=AudioMode.ADD):
    """Superimpose one clip on another, in the center of each frame, starting at
    a given time."""
    require_clip(under_clip, "under clip")
    require_clip(over_clip, "over clip")
    require_float(start_time, "start time")
    require_non_negative(start_time, "start time")

    x = int(under_clip.width()/2) - int(over_clip.width()/2)
    y = int(under_clip.height()/2) - int(over_clip.height()/2)

    return composite(Element(under_clip, 0, [0,0], VideoMode.REPLACE),
                     Element(over_clip, start_time, [x,y], VideoMode.REPLACE, audio_mode))

def loop(clip, length):
    """Repeat a clip as needed to fill the given length."""
    require_clip(clip, "clip")
    require_float(length, "length")
    require_positive(length, "length")

    full_plays = int(length/clip.length())
    partial_play = length - full_plays*clip.length()
    return chain(full_plays*[clip], slice_clip(clip, 0, partial_play))

class ken_burns(MutatorClip):
    """Pan and/or zoom through a clip over time."""
    def __init__(self, clip, width, height, start_top_left, start_bottom_right,
                 end_top_left, end_bottom_right):
        super().__init__(clip)

        # So. Many. Ways to mess up.
        require_int_point(start_top_left, "start top left")
        require_int_point(start_bottom_right, "start bottom right")
        require_int_point(end_top_left, "end top left")
        require_int_point(end_bottom_right, "end bottom right")
        require_non_negative(start_top_left[0], "start top left x")
        require_non_negative(start_top_left[1], "start top left y")
        require_non_negative(end_top_left[0], "end top left x")
        require_non_negative(end_top_left[1], "end top left y")
        require_less(start_top_left[0], start_bottom_right[0],
                     "start top left x", "start bottom right x")
        require_less(start_top_left[1], start_bottom_right[1],
                     "start top left y", "start bottom right y")
        require_less(end_top_left[0], end_bottom_right[0],
                     "end top left x", "end bottom right x")
        require_less(end_top_left[1], end_bottom_right[1],
                     "end top left y", "end bottom right y")
        require_less_equal(start_bottom_right[0], clip.width(),
                           "start bottom right x", "clip width")
        require_less_equal(start_bottom_right[1], clip.height(),
                           "start bottom right y", "clip height")
        require_less_equal(end_bottom_right[0], clip.width(),
                           "end bottom right x", "clip width")
        require_less_equal(end_bottom_right[1], clip.height(),
                           "end bottom right y", "clip height")


        start_ratio = ((start_bottom_right[0] - start_top_left[0])
                       / (start_bottom_right[1] - start_top_left[1]))

        end_ratio = ((end_bottom_right[0] - end_top_left[0])
                     / (end_bottom_right[1] - end_top_left[1]))

        output_ratio = width/height

        if not math.isclose(start_ratio, output_ratio, abs_tol=0.01):
            raise ValueError("This ken_burns effect will distort the image at the start. "
                             f'Starting aspect ratio is {start_ratio}. '
                             f'Output aspect ratio is {output_ratio}. ')

        if not math.isclose(end_ratio, output_ratio, abs_tol=0.01):
            raise ValueError("This ken_burns effect will distort the image at the end. "
                             f'Ending aspect ratio is {end_ratio}. '
                             f'Output aspect ratio is {output_ratio}. ')

        self.start_top_left = np.array(start_top_left)
        self.start_bottom_right = np.array(start_bottom_right)
        self.end_top_left = np.array(end_top_left)
        self.end_bottom_right = np.array(end_bottom_right)

        self.metrics = Metrics(src=clip.metrics,
                               width=width,
                               height=height)

    def get_corners(self, index):
        """ Return the top left and bottom right corners of the view at the
        given frame index. """
        alpha = index/self.clip.num_frames()
        p1 = (((1-alpha)*self.start_top_left + alpha*self.end_top_left))
        p2 = (((1-alpha)*self.start_bottom_right + alpha*self.end_bottom_right))
        p1 = np.around(p1).astype(int)
        p2 = np.around(p2).astype(int)
        return p1, p2

    def frame_signature(self, index):
        p1, p2 = self.get_corners(index)
        return ['ken_burns', {'top_left': p1,
                              'bottom_right': p2,
                              'frame':self.clip.frame_signature(index)}]

    def get_frame(self, index):
        p1, p2 = self.get_corners(index)
        frame = self.clip.get_frame(index)
        fragment = frame[p1[1]:p2[1],p1[0]:p2[0],:]
        sized_fragment = cv2.resize(fragment, (self.width(), self.height()))
        return sized_fragment


def fade_between(clip1, clip2):
    """ Fade from one clip to another.  Both must have the same length. """
    require_clip(clip1, "first clip")
    require_clip(clip2, "second clip")
    require_equal(clip1.length(), clip2.length(), "clip lengths")

    return chain(clip1, clip2, fade_time=clip1.length())

class silence_audio(MutatorClip):
    """ Replace whatever audio we have with silence. """
    def get_samples(self):
        return np.zeros([self.metrics.num_samples(), self.metrics.num_channels])

