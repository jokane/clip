from zipfile import ZipFile
import glob
import hashlib
import io

import pdf2image
import scipy.signal


class resample(Audio):
    """
    Change both the sample rate of an audio clip and its length, using some sort
    of fancy resampling algorithm.
    """

    def __init__(self, audio, new_sample_rate, new_length):
        assert isinstance(audio, Audio)
        assert isfloat(new_sample_rate)
        assert isinstance(new_length, int)
        self.audio = audio
        self.new_sample_rate = new_sample_rate
        self.new_length = new_length

    def __repr__(self):
        return f'resample({self.audio}, {self.new_sample_rate}, {self.new_length})'

    def sample_rate(self):
        return self.new_sample_rate

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.new_length

    def compute_samples(self):
        data = self.audio.get_samples()
        x = scipy.signal.resample(data, self.new_length)
        return x

class fade_audio(Audio):
    """Fade between two sounds, which must be equal in length, sample rate, and number of channels."""

    def __init__(self, audio1, audio2):
        assert isinstance(audio1, Audio)
        assert isinstance(audio2, Audio)
        assert audio1.sample_rate() == audio2.sample_rate(), "Mismatched sample rates %d and %d" % (audio1.sample_rate(), audio2.sample_rate())
        assert audio1.num_channels() == audio2.num_channels()
        assert audio1.length() == audio2.length(), f'Cannot fade audio because the lengths do not match. {audio1.length()} != {audio2.length()}'

        self.audio1 = audio1
        self.audio2 = audio2

    def __repr__(self):
        return 'fade_audio(%s, %s)' % (self.audio1.__repr__(), self.audio2.__repr__())

    def sample_rate(self):
        return self.audio1.sample_rate()

    def num_channels(self):
        return self.audio1.num_channels()

    def length(self):
        return self.audio1.length()

    def compute_samples(self):
        if self.length() > 1e8:
            print("Starting fade_audio.compute_samples on a long segment.    Hold onto your hat.")
        a1 = self.audio1.get_samples()
        a2 = self.audio1.get_samples()
        data = (
            np.linspace([1.0]*self.num_channels(), [0.0]*self.num_channels(), self.length()) * a1
            +
            np.linspace([0.0]*self.num_channels(), [1.0]*self.num_channels(), self.length()) * a2
        )
        return data

        # It's amazing how slow the naive version is...
        # a1 = self.audio1.get_samples()
        # a2 = self.audio2.get_samples()
        # r = np.zeros((self.length(), self.num_channels()))
        # for index in range(0, self.length()):
        #     a = self.alpha(index)
        #     r[index] = (1-a)*a1[index] + a*a2[index]
        # return r

class fade(Clip):
    """Fade between two clips, which must be equal in length, frame size, frame rate, sample rate, and number of channels."""
    def __init__(self, clip1, clip2):
        assert isinstance(clip1, Clip)
        assert isinstance(clip2, Clip)
        assert clip1.frame_rate() == clip2.frame_rate(), "Mismatched frame rates %d and %d" % (clip1.frame_rate(), clip2.frame_rate())
        assert clip1.width() == clip2.width(), f'Mismatched widths {clip1.width()} and {clip2.width()}.'
        assert clip1.height() == clip2.height()
        assert clip1.length() == clip2.length()
        assert clip1.get_audio().sample_rate() == clip2.get_audio().sample_rate(), f'Cannot fade between audio with sample rate {clip1.get_audio().sample_rate()} and audio with sample rate {clip2.get_audio().sample_rate()}.'

        assert clip1.get_audio().num_channels() == clip2.get_audio().num_channels(), f'Cannot fade between audio with {clip1.get_audio().num_channels()} channel(s) and audio with {clip2.get_audio().num_channels()} channel(s).'

        assert clip1.get_audio().length() == clip2.get_audio().length(), f'Cannot fade between clips because their audio lengths do not match. {clip1.get_audio().length()} != {clip2.get_audio().length()}'

        self.clip1 = clip1
        self.clip2 = clip2

    def __repr__(self):
        return f'fade({self.clip1}, {self.clip2})'

    def frame_rate(self):
        return self.clip1.frame_rate()

    def width(self):
        return self.clip1.width()

    def height(self):
        return self.clip1.height()

    def length(self):
        return self.clip1.length()

    def alpha(self, index):
        return (self.clip1.length()-1 - index)/(self.clip1.length())

    def frame_signature(self, index):
        a = self.alpha(index)
        return "(%f%s + %f%s)" % (a, self.clip1.frame_signature(index), 1-a, self.clip2.frame_signature(index))

    def get_frame(self, index):
        a = self.alpha(index)
        return cv2.addWeighted(
            self.clip1.get_frame(index), a,
            self.clip2.get_frame(index), 1.0-a,
            0
        )

    def get_audio(self):
        return fade_audio(self.clip1.get_audio(), self.clip2.get_audio())


def slice_out(clip, start, end):
    return chain(slice(clip, 0, start), slice(clip, end, clip.length()))

def scale_to_fit(clip, max_width, max_height):
    """Scale the frames of a clip to fit within the given constraints,
    maintaining the aspect ratio."""

    aspect1 = clip.width() / clip.height()
    aspect2 = max_width / max_height

    if aspect1 > aspect2:
        # Fill width.
        new_width = max_width
        new_height = clip.height() * max_width / clip.width()
    else:
        # Fill height.
        new_height = max_height
        new_width = clip.width() * max_height / clip.height()

    return scale_to_size(clip, int(new_width), int(new_height))

def letterbox(clip, width, height):
    clip = scale_to_fit(clip, width, height)
    background = black(height, width, clip.frame_rate(), clip.length())
    a = clip.get_audio()
    background = replace_audio(background, silence(a.length(), a.sample_rate(), a.num_channels()))
    return superimpose(background, clip, int((background.width()-clip.width())/2), int((background.height()-clip.height())/2), 0, audio='replace')


class image_glob(Clip):
    """Form a video from a collection of identically-sized image files that match
    a unix-style pattern, at a given frame rate."""

    def __init__(self, pattern, frame_rate):
        self.pattern = pattern
        assert isfloat(frame_rate)
        assert frame_rate > 0

        self.frame_rate_ = frame_rate
        self.filenames = sorted(glob.glob(pattern))
        assert len(self.filenames) > 0, "No files matched pattern: " + pattern
        self.sample_frame = cv2.imread(self.filenames[0])
        assert self.sample_frame is not None

    def __repr__(self):
        return f'image_glob({self.pattern}, {self.frame_rate})'

    def frame_rate(self):
        return self.frame_rate_

    def width(self):
        return self.sample_frame.shape[1]

    def height(self):
        return self.sample_frame.shape[0]

    def length(self):
        return len(self.filenames)

    def frame_signature(self, index):
        return self.filenames[index]

    def get_frame(self, index):
        return cv2.imread(self.filenames[index])

    def get_audio(self):
        return self.default_audio()

class repeat_frame(Clip):
    """A clip that shows the same frame, from another clip, over and over."""
    def __init__(self, clip, frame_index, length):
        assert isinstance(clip, Clip)

        assert isinstance(frame_index, int)
        assert frame_index >= 0
        assert frame_index < clip.length(), "Trying to repeat frame %d of %s, but the last valid frame index is %s." % (frame_index, clip.signature(), clip.length()-1)

        assert isinstance(length, int)
        assert length > 0

        self.clip = clip
        self.frame_index = frame_index
        self.length_ = length

    def __repr__(self):
        return f'repeat_frame({self.clip}, {self.frame_index}, {self.length_})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def length(self):
        return self.length_

    def width(self):
        return self.clip.width()

    def height(self):
        return self.clip.height()

    def frame_signature(self, index):
        return self.clip.frame_signature(self.frame_index)

    def get_frame(self, index):
        return self.clip.get_frame(self.frame_index)

    def get_audio(self):
        return self.default_audio()


class force_framerate(Clip):
    """Change the frame rate at which a clip thinks it should be played.    Audio is padded or truncated to match, and thus is likely to become out-of-sync."""
    def __init__(self, clip, frame_rate):
        assert isinstance(clip, Clip)
        assert isfloat(frame_rate)
        assert frame_rate > 0

        self.clip = clip
        self.frame_rate_ = frame_rate
        self.audio = clip.get_audio()
        target_length = self.frame_to_sample(self.length())
        self.audio = force_audio_length(self.audio, target_length)

    def __repr__(self):
        return f'force_framerate({self.clip}, {self.frame_rate_})'

    def frame_rate(self):
        return self.frame_rate_
    
    def width(self):
        return self.clip.width()
    
    def height(self):
        return self.clip.height()
    
    def length(self):
        return self.clip.length()
    
    def get_frame(self, index):
        return self.clip.get_frame(index)
    
    def frame_signature(self, index):
        return self.clip.frame_signature(index)
    
    def get_audio(self):
        return self.audio

def fade_in(clip, fade_frames, color=(0,0,0)):
    """Fade in from a solid color, defaulting to black."""
    assert isinstance(clip, Clip)
    assert isinstance(fade_frames, int)
    assert fade_frames >= 0
    assert fade_frames <= clip.length(), "Cannot fade into %s for %f frames, because the clip is only %f frames long." % (clip, fade_frames, clip.length())
    assert iscolor(color)
    blk = solid(clip.height(), clip.width(), clip.frame_rate(), fade_frames, color=color)
    return fade_chain(fade_frames, blk, clip)


class resample_frames(Clip):
    """
    Modify the frame rate and the length of the video.    No change to the audio.
    """
    def __init__(self, clip, new_frame_rate, new_length):
        assert isinstance(clip, Clip)
        assert isfloat(new_frame_rate)
        assert isinstance(new_length, int)
        self.clip = clip
        self.new_frame_rate = new_frame_rate
        self.new_length = new_length

    def new_index(self, index):
        x = int(self.clip.length()*index/self.new_length)
        return x
    def __repr__(self):
        return f'resample_frames({self.clip}, {self.new_frame_rate}, {self.new_length})'
    def frame_rate(self):
        return self.new_frame_rate
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.new_length
    def frame_signature(self, index):
        return self.clip.frame_signature(self.new_index(index))
    def get_frame(self, index):
        return self.clip.get_frame(self.new_index(index))
    def get_audio(self):
        return self.clip.get_audio()

def timewarp(clip, factor):
    assert isinstance(clip, Clip)
    assert isfloat(factor)
    assert factor > 0
    a = clip.get_audio()
    x = resample_frames(clip, clip.frame_rate(), int(clip.length()*factor))
    a = timewarp_audio(a, factor)
    x = replace_audio(x, a)
    return x

def change_framerate(clip, new_frame_rate):
    assert isinstance(clip, Clip)
    assert isfloat(new_frame_rate)
    assert new_frame_rate > 0
    new_length = int(new_frame_rate*clip.length()/clip.frame_rate())
    return resample_frames(clip, new_frame_rate, new_length)

class pdf_page(Clip):
    """A silent video constructed from a single page of a PDF."""
    def __init__(self, pdf, page_num, length, frame_rate, **kwargs):
        assert isinstance(length, int)
        assert length > 0, f'Cannot create a PDF clip with length {length}.'
        self.pdf = pdf
        self.page_num = page_num
        self.frame_rate_ = frame_rate
        self.length_ = length
        self.hash = sha256sum(self.pdf)
        self.kwargs = kwargs
        images = pdf2image.convert_from_path(self.pdf, first_page=page_num, last_page=page_num, **kwargs)
        self.the_frame = np.array(images[0])

        # The code above seems sometimes (or always?) to give an image that has the
        # red and blue channels swapped.    Fix it.
        if images[0].mode == 'RGB':
            self.the_frame = self.the_frame[:,:,::-1]
        else:
            print("Tread carefully, because I'm not sure if a PIL image from {pdf}, which has mode {images[0].mode} needs to have channels swapped.")

        # The code above seems sometimes to return an image that is not the
        # correct size, off by one in the width.    Fix it.
        if 'size' in kwargs:
            w = kwargs['size'][0]
            h = kwargs['size'][1]
            if h != self.the_frame.shape[0] or w != self.the_frame.shape[1]:
                self.the_frame = self.the_frame[0:h,0:w]

    def __repr__(self):
        return f'pdf_page({self.pdf}, {self.page_num}, {self.length_}, {self.frame_rate_}, {self.kwargs})'
    def frame_rate(self):
        return self.frame_rate_
    def width(self):
        return self.the_frame.shape[1]
    def height(self):
        return self.the_frame.shape[0]
    def length(self):
        return self.length_
    def get_audio(self):
        return self.default_audio()
    def frame_signature(self, index):
        return f'pdf_page: {self.pdf}, {self.hash[:5]}, {self.page_num}, {self.kwargs})'
    def get_frame(self, index):
        return self.the_frame


class zip_file(Clip):
    def __init__(self, fname, frame_rate=None):
        assert isinstance(fname, str)
        assert os.path.isfile(fname), f'Trying to open {fname}, which does not exist.'
        self.fname = fname
        self.zf = ZipFile(fname, 'r')

        image_formats = ['tga']    # Many others are likely to work, but haven't been tested.
        pattern = ".(" + "|".join(image_formats) + ")$"

        self.info_list = sorted(filter(lambda x: re.search(pattern, x.filename), self.zf.infolist()), key=lambda x: x.filename)

        assert isfloat(frame_rate)
        assert frame_rate > 0
        self.frame_rate_ = frame_rate

        self.sample_frame = self.get_frame(0)

    def __repr__(self):
        return f'zip_file("{self.fname}", frame_rate={self.frame_rate_})'

    def frame_rate(self):
        return self.frame_rate_

    def width(self):
        return self.sample_frame.shape[1]

    def height(self):
        return self.sample_frame.shape[0]

    def length(self):
        return len(self.info_list)

    def frame_signature(self, index):
        return f"zip_file_member({self.fname}, {self.info_list[index].filename})"

    def get_frame(self, index):
        data = self.zf.read(self.info_list[index])
        pil_image = Image.open(io.BytesIO(data)).convert('RGB')
        frame = np.array(pil_image)
        frame = frame[:,:,::-1]
        return frame

    def get_audio(self):
        return self.default_audio()

def sha256sum(filename):
    # https://stackoverflow.com/questions/22058048/hashing-a-file-in-python
    h = hashlib.sha256()
    b = bytearray(128*1024)
    mv = memoryview(b)
    with open(filename, 'rb', buffering=0) as f:
        for n in iter(lambda: f.readinto(mv), 0):
            h.update(mv[:n])
    return h.hexdigest()

# This bit from the ffprobe output was relevant for some video:
match = re.search(r'displaymatrix: rotation of -90.00 degrees', deets)
if match:
    self.width_, self.height_ = self.height_, self.width_

class audio_from_data(Audio):
    """ Form an audio clip from a numpy array. """
    def __init__(self, name, data, sample_rate):
        assert isinstance(name, str)
        assert isinstance(data, np.ndarray)
        assert isfloat(sample_rate)
        self.name = name
        self.data = data
        self.sample_rate_ = sample_rate

    def __repr__(self):
        return "audio_from_data('%s', [%d samples], %s)" % (self.name, self.data.shape[0], self.sample_rate_)

    def length(self):
        return self.data.shape[0]

    def sample_rate(self):
        return self.sample_rate_

    def num_channels(self):
        return self.data.shape[1]

    def compute_samples(self):
        return self.data


def audio_file(fname):
    assert isinstance(fname, str)
    assert os.path.isfile(fname), f'Trying to open {fname}, which does not exist.'

    direct_formats = list(map(lambda x: "." + x.lower(), soundfile.available_formats().keys()))
    video_formats = ['.mp4', '.mov', '.mkv', '.wmv']

    ext = os.path.splitext(fname)[1].lower()
    if ext in direct_formats:
        data, sample_rate = soundfile.read(fname, always_2d=True)
        return audio_from_data(fname, data, sample_rate)

    if ext in video_formats:
        cached_filename, success = cache.lookup(fname, 'flac')
        if not success:
            print(f'Extracting audio from {fname}')
            with tempfile.TemporaryDirectory() as td:
                audio_fname = os.path.join(td, 'audio.flac')
                ffmpeg(
                    f'-i {fname}',
                    f'-vn',
                    f'{audio_fname}',
                )
                os.rename(audio_fname, cached_filename)
                cache.insert(cached_filename)
        return audio_file(cached_filename)

    raise Exception(f"Don't know how to extract audio from {ext} format: {fname}")

def silence(length, sample_rate, num_channels):
    """ Create an audio clip of the requested amount of silence. """
    return audio_from_data("silence", np.zeros((length, num_channels)), sample_rate)

class slice_audio(Audio):
    """Extract the portion of a sound between the given times, which are specified in samples."""
    def __init__(self, audio, start_sample, end_sample):
        assert isinstance(audio, Audio)
        assert isinstance(start_sample, int)
        assert isinstance(end_sample, int)
        assert start_sample >= 0, f"Slicing {audio} but slice start should be at least 0.    Got {start_sample} instead."
        assert end_sample <= audio.length(), "Slice end %d is beyond the end of the sound (%d)" % (end_sample, audio.length())

        assert start_sample <= end_sample, "Slice end %d is before slice start %d" % (end_sample, start_sample)

        self.audio = audio
        self.start_sample = start_sample
        self.end_sample = end_sample

    def __repr__(self):
        return f'slice_audio({self.audio}, {self.start_sample}, {self.end_sample})'

    def sample_rate(self):
        return self.audio.sample_rate()

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.end_sample - self.start_sample

    def compute_samples(self):
        return self.audio.get_samples()[self.start_sample:self.end_sample]


class mix(Audio):
    """
    Add together a series of audio clips, sample by sample.    The sample rates
    and number of channels must match.    The resulting length will match the
    longest of the input clips.
    """

    def __init__(self, *args):
        # Construct our list of audios.
        self.audios = list()
        for x in args:
            if isiterable(x):
                self.audios += x
            else:
                self.audios.append(x)

        # Sanity checks.
        for audio in self.audios: assert isinstance(audio, Audio)
        assert len(self.audios) > 0, "Need at least one audio to mix."
        assert len(set(map(lambda x: x.sample_rate(), self.audios))) == 1, "Cannot chain audios because the sample rates do not match." + str(list(map(lambda x: x.sample_rate(), self.audios)))
        assert len(set(map(lambda x: x.sample_rate(), self.audios))) == 1, "Cannot chain audios because the numbers of channels do not match." + str(list(map(lambda x: x.num_channels(), self.audios)))

    def __repr__(self):
        return f'mix({self.audios})'

    def sample_rate(self):
        return self.audios[0].sample_rate()

    def num_channels(self):
        return self.audios[0].num_channels()

    def length(self):
        return max(map(lambda x: x.length(), self.audios))

    def compute_samples(self):
        r = np.zeros((self.length(), self.num_channels()))
        for audio in self.audios:
            r[:audio.length()] += audio.get_samples()
        return r

class mix_at(Audio):
    """
    Add together a series of audio clips, sample by sample, each starting at
    given sample.    Arguments should be (audio, start) tuples.    The sample rates
    and number of channels must match.
    """

    def __init__(self, *args):
        for tup in args:
            assert isinstance(tup, tuple)
            audio, start = tup
            assert isinstance(audio, Audio)
            assert isinstance(start, int)

        self.tups = args

        assert len(self.tups) > 0, "Need at least one audio to mix."
        assert len(set(map(lambda x: x[0].sample_rate(), self.tups))) == 1, "Cannot mix audios because the sample rates do not match." + str(list(map(lambda x: x[0].sample_rate(), self.tups)))
        assert len(set(map(lambda x: x[0].sample_rate(), self.tups))) == 1, "Cannot mix audios because the numbers of channels do not match." + str(list(map(lambda x: x.num_channels(), self.tups)))

    def __repr__(self):
        return f'mix_at({self.tups})'

    def sample_rate(self):
        return self.tups[0][0].sample_rate()

    def num_channels(self):
        return self.tups[0][0].num_channels()

    def length(self):
        return max(map(lambda x: x[0].length() + x[1], self.tups))

    def compute_samples(self):
        r = np.zeros((self.length(), self.num_channels()))
        for audio, start in self.tups:
            r[start:start+audio.length()] += audio.get_samples()
        return r

class volume(Audio):
    """
    Scale the volume of an audio clip, sample by sample.
    """

    def __init__(self, audio, factor):
        assert isinstance(audio, Audio)
        assert isfloat(factor)
        self.audio = audio
        self.factor = factor

    def __repr__(self):
        return f'volume({self.audio}, factor)'

    def sample_rate(self):
        return self.audio.sample_rate()

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.audio.length()

    def compute_samples(self):
        return self.factor * self.audio.get_samples()

def change_sample_rate(audio, new_sample_rate):
    return resample(audio, new_sample_rate, round(audio.length() * new_sample_rate/audio.sample_rate()))

def timewarp_audio(audio, factor):
    return resample(audio, audio.sample_rate(), int(audio.length()*factor))

class chain_audio(Audio):
    """
    Concatenate a series of audio clips.    The clips may be given individually, in
    lists, or a mixture of both.

    The sample rates and number of channels must match.
    """

    def __init__(self, *args):
        # Construct our list of audios.
        self.audios = list()
        for x in args:
            if isiterable(x):
                self.audios += x
            else:
                self.audios.append(x)

        # Sanity checks.
        for audio in self.audios: assert isinstance(audio, Audio)
        assert len(self.audios) > 0, "Need at least one audio to form a chain."
        assert len(set(map(lambda x: x.sample_rate(), self.audios))) == 1, "Cannot chain audios because the sample rates do not match." + str(list(map(lambda x: x.sample_rate(), self.audios)))
        assert len(set(map(lambda x: x.num_channels(), self.audios))) == 1, "Cannot chain audios because the numbers of channels do not match." + str(list(map(lambda x: x.num_channels(), self.audios)))

    def __repr__(self):
        return f'chain_audio({self.audios})'

    def sample_rate(self):
        return self.audios[0].sample_rate()

    def num_channels(self):
        return self.audios[0].num_channels()

    def length(self):
        return sum(map(lambda x: x.length(), self.audios))

    def compute_samples(self):
        chunks = list(map(lambda x: x.get_samples(), self.audios))
        return np.concatenate(chunks)

def force_audio_length(audio, target_length):
    """Return an audio clip with exactly the given length.    Trim the end or add silence to achieve this."""
    if audio.length() < target_length:
        return chain_audio(audio, silence(target_length-audio.length(), audio.sample_rate(), audio.num_channels()))
    elif audio.length() > target_length:
        return slice_audio(audio, 0, target_length)
    else:
        return audio



class reverse_audio(Audio):
    """Same sound, played backward."""

    def __init__(self, audio):
        assert isinstance(audio, Audio)
        self.audio = audio

    def __repr__(self):
        return 'reverse_audio(%s)' % (self.audio.__repr__())

    def sample_rate(self):
        return self.audio.sample_rate()

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.audio.length()

    def compute_samples(self):
        return np.flip(self.audio.get_samples(), axis=0)


if sys.version_info.major == 3 and sys.version_info.minor < 8:
    Label = collections.namedtuple('Label', ['text', 'color', 'font', 'size', 'x', 'y', 'start', 'end'])
else:
    Label = collections.namedtuple('Label', ['text', 'color', 'font', 'size', 'x', 'y', 'start', 'end'], defaults=[None]*4)


def get_font(font, size):
    """
    Return a TrueType font for use on Pillow images, with caching to prevent
    loading the same font again and again.    (The performance improvement seems to
    be small but non-zero.)
    """
    if (font, size) not in get_font.cache:
        try:
            get_font.cache[(font, size)] = ImageFont.truetype(font, size)
        except OSError:
            raise Exception(f"Failed to open font {font}.")
    return get_font.cache[(font, size)]
get_font.cache = dict()

class add_labels(Clip):
    """
    Superimpose one or more text labels onto every frame of a clip.
    """

    def __init__(self, clip, labels):
        assert isinstance(clip, Clip)
        assert isiterable(labels)

        # If we just got one label, pretend it was a list.
        if isinstance(labels, Label):
            labels = [labels]

        for (i, label) in enumerate(labels):
            assert isinstance(label, Label)
            assert isfloat(label.size)
            assert isinstance(label.font, str)
            assert isinstance(label.text, str)
            assert isinstance(label.x, int), f'Got {type(label.x)} instead of int for label x.'
            assert isinstance(label.y, int)
            assert iscolor(label.color)

            if label.start is None:
                labels[i] = label._replace(start=0)
                label = labels[i]

            if label.end is None:
                labels[i] = label._replace(end=clip.length())
                label = labels[i]

            assert isinstance(label.start, int), f"Label start frame should be an integer, not {label.start}."
            assert isinstance(label.end, int)

        self.clip = clip
        self.labels = labels

    def __repr__(self):
        return 'add_labels(%s, %s)' % (self.clip.__repr__(), self.labels)

    def frame_rate(self):
        return self.clip.frame_rate()
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.clip.length()
    def frame_signature(self, index):
        return self.clip.frame_signature(index) + "+" + ",".join(map(lambda x: f'"{x.text}" {x.color} {x.font} {x.size} {x.x} {x.y}', filter(lambda x: x.start <= index and index < x.end, self.labels)))

    def get_frame(self, index):
        frame = self.clip.get_frame(index)
        pil_image = Image.fromarray(frame)
        draw = ImageDraw.Draw(pil_image)

        for label in self.labels:
            if label.start <= index and index < label.end:
                font = get_font(label.font, label.size)
                draw.text((label.x, label.y), label.text, font=font, fill=(label.color[2],label.color[1],label.color[0]))

        array = np.array(pil_image)
        return array

    def get_audio(self):
        return self.clip.get_audio()

def add_titles(clip, labels, x=None, y=None, halign="center", valign="center", lalign="center", spacing=1.2):
    """
    Add several labels, with the locations computed to stack nicely. The
    labels parameter should be an iterable of Labels, whose positions are
    ignored.
    """

    # If we just got one label, pretend it was a list.
    if isinstance(labels, Label):
        labels = [labels]

    # Make a dummy frame, so we can compute text sizes.
    pil_image = Image.new("RGB", (clip.width(), clip.height()))
    draw = ImageDraw.Draw(pil_image)

    # Figure out how big the rectangle containing the titles needs to be.
    width = 0
    height = 0
    for label in labels:
        font = get_font(label.font, label.size)
        size = draw.textsize(label.text, font=font)
        width = max(width, size[0])
        height += int(spacing * size[1])

    # If we didn't get an x or y position, use the center of the frame.
    if x is None:
        x = int(clip.width()/2)
    if y is None:
        y = int(clip.height()/2)

    # Figure out where the top left corner of the box should be placed.
    if halign == 'left':
        left = x
    elif halign == 'right':
        left = x - width
    elif halign == 'center':
        left = x - int(width/2)
    else:
        raise Exception(f'Unknown halign {halign}.')

    if valign == 'top':
        top = y
    elif valign == 'bottom':
        top = y - height
    elif valign == 'center':
        top = y - int(height/2)
    else:
        raise Exception(f'Unknown valign {valign}.')

    # Create labels positioned correctly within that box.
    new_labels = list()
    y = top
    for label in labels:
        font = get_font(label.font, label.size)
        size = draw.textsize(label.text, font=font)

        if lalign == 'left':
            x = left
        elif lalign == 'right':
            x = left + width - size[0]
        elif lalign == 'center':
            x = left + int((width - size[0])/2)
        else:
            raise Exception(f'Unknown lalign {lalign}.')

        new_label = label._replace(x=x, y=y)
        new_labels.append(new_label)
        y += int(spacing * size[1])

    # Return an add_labels that uses these correctly-positioned new labels.
    return add_labels(clip, new_labels)

class chain(Clip):
    """
    Concatenate a series of clips.    The clips may be given individually, in
    lists, or a mixture of both.
    """

    def __init__(self, *args):
        # Construct our list of clips.
        self.clips = list()
        for x in args:
            if isiterable(x):
                self.clips += x
            else:
                self.clips.append(x)
        for clip in self.clips: assert isinstance(clip, Clip), f'Got {type(clip)} instead of Clip.'
        assert len(self.clips) > 0, "Need at least one clip to form a chain."

        assert len(set(map(lambda x: x.width(), self.clips))) == 1, "Cannot chain clips because the widths do not match. " + str(list(map(lambda x: x.width(), self.clips)))
        assert len(set(map(lambda x: x.height(), self.clips))) == 1, "Cannot chain clips because the heights do not match. " + str(list(map(lambda x: x.height(), self.clips)))
        assert len(set(map(lambda x: x.frame_rate(), self.clips))) == 1, "Cannot chain clips because the framerates do not match. " + str(list(map(lambda x: x.frame_rate(), self.clips)))

        self.audio = force_audio_length(chain_audio(map(lambda x: x.get_audio(), self.clips)), self.default_audio().length())
        # TODO: Looks like chain_audio is bad choice here, especially if there are
        # many clips in the chain.    Each one many have a roundoff error in the
        # audio length, and they will all add up.    Instead, let's make a big empty
        # numpy array, and then paste in the data from each clip in the chain at
        # the right place.    That way, the errors won't accumulate they way they do
        # now, necessitating the force_audio_length above.

        # TODO: Where can we verify that each clip has the correct-length audio?
        # Maybe in realize_video()?

    def __repr__(self):
        return f'chain({self.clips})'

    def frame_rate(self):
        return self.clips[0].frame_rate()

    def width(self):
        return self.clips[0].width()

    def height(self):
        return self.clips[0].height()

    def length(self):
        return sum(map(lambda x: x.length(), self.clips))

    def find_frame_index(self, frame_index):
        # Given a frame index for the chained video, find and return the index of
        # the source clip that would contain that frame, along with the index
        # within that clip.    TODO: Binary search.
        for i in range(0, len(self.clips)):
            if frame_index < self.clips[i].length():
                return (i, frame_index)
            frame_index -= self.clips[i].length()
        assert False, f'Could not find chain element index {frame_index} within {len(self.clips)} clips, with lengths {list(map(lambda x: x.length(), self.clips))}    Total length is only {self.length()}.\n{self}'
        return (None, None)

    def frame_signature(self, index):
        i, index = self.find_frame_index(index)
        return self.clips[i].frame_signature(index)

    def get_frame(self, index):
        i, index = self.find_frame_index(index)
        return self.clips[i].get_frame(index)

    def get_audio(self):
        return self.audio


class replace_audio(Clip):
    """
    Replace the audio in a clip with something else, usually forcing the length to match.
    """

    def __init__(self, clip, audio, force_to=None):
        assert isinstance(clip, Clip)
        assert isinstance(audio, Audio)
        self.clip = clip
        self.audio = audio
        if force_to is None:
            force_to = self.frame_to_sample(self.length())
        else:
            assert isinstance(force_to, int)
        self.audio = force_audio_length(self.audio, force_to)

    def __repr__(self):
        return f'replace_audio({self.clip}, {self.audio})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def width(self):
        return self.clip.width()

    def height(self):
        return self.clip.height()

    def length(self):
        return self.clip.length()

    def frame_signature(self, index):
        return self.clip.frame_signature(index)

    def get_frame(self, index):
        return self.clip.get_frame(index)

    def get_audio(self):
        return self.audio


class slice_video(Clip):
    """
    Extract the portion of a clip between the given frames.
    """
    def __init__(self, clip, start, end):
        assert isinstance(clip, Clip)
        assert isinstance(start, int)
        assert isinstance(end, int)
        assert start <= end, "Chopping %s, but end %d is before start %d." % (clip, end, start)
        assert start >= 0
        assert end <= clip.length()

        self.clip = clip

        self.start_frame = start
        self.end_frame = end

        self.audio = clip.get_audio()
        self.audio = slice_audio(
            self.audio,
            self.frame_to_sample(self.start_frame),
            self.frame_to_sample(self.end_frame)
        )

    def __repr__(self):
        return f'slice_video({self.clip}, {self.start_frame}, {self.end_frame})'

    def frame_rate(self):
        return self.clip.frame_rate()
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.end_frame - self.start_frame
    def frame_signature(self, index):
        return self.clip.frame_signature(self.start_frame + index)
    def get_frame(self, index):
        return self.clip.get_frame(self.start_frame + index)
    def get_audio(self):
        return self.audio

class superimpose(Clip):
    """Superimpose one clip on another, at a given place in each frame, starting
    at a given time."""

    def __init__(self, under_clip, over_clip, x, y, start_frame, audio='ignore'):
        assert isinstance(under_clip, Clip)
        assert isinstance(over_clip, Clip)
        assert isinstance(x, int)
        assert x >= 0
        assert isinstance(y, int)
        assert y >= 0
        assert isfloat(start_frame)
        assert start_frame >= 0
        start_frame = int(start_frame)

        assert y + over_clip.height() <= under_clip.height(), f"Superimposing {over_clip} onto {under_clip} at ({x}, {x}), but the under clip is not tall enough.    It would need to be {y+over_clip.height()}, but is only {under_clip.height()}."
        assert x + over_clip.width() <= under_clip.width(), f"Superimposing {over_clip} onto {under_clip} at ({x}, {y}), but the under clip is not wide enough. {x+over_clip.width()} > {under_clip.width()}"
        assert start_frame + over_clip.length() <= under_clip.length(), f"Superimposing {over_clip} onto {under_clip} at frame {start_frame}, but the under clip is not long enough."
        assert under_clip.frame_rate() == over_clip.frame_rate(), f'Superimposing {over_clip} onto {under_clip} at frame {start_frame}, but the framerates do not match ({over_clip.frame_rate()} != {under_clip.frame_rate()}.'

        self.under_clip = under_clip
        self.over_clip = over_clip
        self.x = x
        self.y = y
        self.start_frame = start_frame

        if audio == 'ignore':
            self.audio = under_clip.get_audio()
        elif audio in ['replace', 'mix']:
            original_audio = under_clip.get_audio()
            new_audio = over_clip.get_audio()
            assert original_audio.sample_rate() == new_audio.sample_rate()
            assert original_audio.num_channels() == new_audio.num_channels()

            start_sample = under_clip.frame_to_sample(start_frame)
            end_sample = under_clip.frame_to_sample(start_frame + over_clip.length())

            before = slice_audio(original_audio, 0, start_sample)
            during = slice_audio(original_audio, start_sample, end_sample)
            after = slice_audio(original_audio, end_sample, original_audio.length())

            if audio == 'replace':
                self.audio = chain_audio(before, new_audio, after)
            else: # mix
                self.audio = chain_audio(before, mix(during, new_audio), after)
        else:
            raise Exception(f'Unknown audio mode {self.audio} in superimpose.')

    def __repr__(self):
        return f'superimpose({self.under_clip}, {self.over_clip}, {self.x}, {self.y}, {self.start_frame}, audio={self.audio})'

    def frame_rate(self):
        return self.under_clip.frame_rate()

    def width(self):
        return self.under_clip.width()

    def height(self):
        return self.under_clip.height()

    def length(self):
        return self.under_clip.length()

    def frame_signature(self, index):
        if index >= self.start_frame and index - self.start_frame < self.over_clip.length():
            return "%s+(%s@(%d,%d,%d))" % (self.under_clip.frame_signature(index), self.over_clip.frame_signature(index - self.start_frame), self.x, self.y, self.start_frame)
        return self.under_clip.frame_signature(index)

    def get_frame(self, index):
        frame = np.copy(self.under_clip.get_frame(index))
        if index >= self.start_frame and index - self.start_frame < self.over_clip.length():
            x0 = self.x
            x1 = self.x + self.over_clip.width()
            y0 = self.y
            y1 = self.y + self.over_clip.height()
            frame[y0:y1, x0:x1, :] = self.over_clip.get_frame(index - self.start_frame)
        return frame

    def get_audio(self):
        return self.audio

def superimpose_center(under_clip, over_clip, start_frame, audio='ignore'):
    """Superimpose one clip on another, in the center of each frame, starting at
    a given time."""
    assert isinstance(under_clip, Clip)
    assert isinstance(over_clip, Clip)
    assert isinstance(start_frame, int)
    x = int(under_clip.width()/2) - int(over_clip.width()/2)
    y = int(under_clip.height()/2) - int(over_clip.height()/2)
    return superimpose(under_clip, over_clip, x, y, start_frame, audio)


def fade_out(clip, fade_frames, color=(0,0,0)):
    """Fade out to a solid color, defaulting to black."""
    assert isinstance(clip, Clip)
    assert isinstance(fade_frames, int)
    assert fade_frames >= 0
    assert fade_frames <= clip.length(), "Cannot fade out from %s for %f frames, because the clip is only %f frames long." % (clip, fade_frames, clip.length())

    blk = solid(clip.height(), clip.width(), clip.frame_rate(), fade_frames, color=color)
    return fade_chain(fade_frames, clip, blk)

def loop(clip, length):
    "Repeat a clip as needed to fill the given length."
    assert isinstance(clip, Clip)
    assert isinstance(length, int)
    assert length > 0
    full_plays = int(length/clip.length())
    partial_play = length - full_plays*clip.length()
    return chain(full_plays*[clip], slice_video(clip, 0, partial_play))


# Rendering speed for preset for ffmpeg.  Handles the tradeoff between
# rendering speed and output quality.
# Choose from:
#   ultrafast superfast veryfast faster fast medium slow slower veryslow
# Apparently, the instructions are to "use the slowest preset you have patience
# for."
Clip.preset = 'slower'

# Target bitrate.  Handles the tradeoff between file size and output quality.
Clip.bitrate = '1024k'
# Clip.bitrate = '120k'  <-- Heavily compressed to meet 20mb upload limit.


def fix_dimensions(x):
  if x.width() != width or x.height() != height:
    x = letterbox(x, width, height)

  a = x.get_audio()
  changed = False
  if a.sample_rate() != sample_rate:
    a = change_sample_rate(a, sample_rate)
    changed = True

  if a.num_channels() != 2:
    a = mono_to_stereo(a)
    changed = True
  
  if changed:
    x = replace_audio(x, a)

  if x.frame_rate() != frame_rate:
    x = change_framerate(x, frame_rate)

  return x

class horizontal_scroll(Clip):
    def __init__(self, clip, frame_index, width):
        assert isinstance(clip, Clip) 
        assert isinstance(frame_index, int)
        assert isinstance(width, int)

        self.clip = clip
        self.frame_index = frame_index
        self.width_ = width

        self.source_frame = clip.get_frame(frame_index)

    def __repr__(self):
        return f'horizontal_scroll({self.clip}, {self.frame_index}, {self.width_})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def length(self):
        return self.source_frame.shape[1] - self.width_

    def width(self):
        return self.width_

    def height(self):
        return self.source_frame.shape[0]

    def frame_signature(self, index):
        return f"%s hs:%s/%s" % (self.clip.frame_signature(self.frame_index), self.width_, index)

    def get_frame(self, index):
        x = self.source_frame[:,index:index+self.width_,:]
        return x

    def get_audio(self):
        return self.clip.get_audio()

def pad_to_length(clip, target_length):
    if clip.length() < target_length:
        clip = chain(clip, black(height, width, frame_rate, target_length - clip.length()))
    return clip


def static_image(filename, frame_rate, length):
    the_frame = cv2.imread(filename)
    assert the_frame is not None
    return static_frame(filename, the_frame, frame_rate, length)


class static_frame(Clip):
    def __init__(self, frame_name, the_frame, frame_rate, length):
        assert isfloat(frame_rate)
        assert frame_rate > 0

        assert the_frame is not None

        self.frame_name = frame_name
        self.frame_rate_ = frame_rate
        self.length_ = length
        self.the_frame = the_frame

    def __repr__(self):
        return f'static_frame({self.frame_name}, {self.frame_rate_}, {self.length_})'

    def frame_rate(self):
        return self.frame_rate_

    def width(self):
        return self.the_frame.shape[1]

    def height(self):
        return self.the_frame.shape[0]

    def length(self):
        return self.length_

    def frame_signature(self, index):
        return f'{self.__repr__()}:{index}'

    def get_frame(self, index):
        return self.the_frame

    def get_audio(self):
        return self.default_audio()

class ken_burns(Clip):
    def __init__(self, clip, width, height, start_top_left, start_bottom_right, end_top_left, end_bottom_right):
        self.clip = clip
        self.width_ = width
        self.height_ = height
        self.start_top_left = np.array(start_top_left)
        self.start_bottom_right = np.array(start_bottom_right)
        self.end_top_left = np.array(end_top_left)
        self.end_bottom_right = np.array(end_bottom_right)

    def __repr__(self):
        return f'ken_burns({self.clip}, {self.width_}, {self.height_}, {self.start_top_left}, {self.start_bottom_right}, {self.end_top_left}, {self.end_bottom_right})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def frame_signature(self, index):
        return f'{self.__repr__()}:f{index}'

    def get_audio(self):
        return self.clip.get_audio()
    
    def height(self):
        return self.height_

    def width(self):
        return self.width_

    def length(self):
        return self.clip.length()

    def get_frame(self, index):
        alpha = index/self.clip.length()
        frame = self.clip.get_frame(index)
        p1 = (((1-alpha)*self.start_top_left + alpha*self.end_top_left)).astype(int)
        p2 = (((1-alpha)*self.start_bottom_right + alpha*self.end_bottom_right)).astype(int)
        fragment = frame[p1[1]:p2[1],p1[0]:p2[0],:]
        sized_fragment = cv2.resize(fragment, (self.width_, self.height_))
        #print(f"ken_burns: index={index} alpha={alpha} p1={p1} p2={p2} fragment.shape={fragment.shape} sized_fragment.shape={sized_fragment.shape}")
        return sized_fragment



def fade_out_audio(audio, samples):
    first_part = slice_audio(audio, 0, audio.length()-samples)
    second_part = slice_audio(audio, audio.length()-samples, audio.length())
    out = silence(second_part.length(), second_part.sample_rate(), second_part.num_channels())
    second_part = fade_audio(second_part, out)
    return chain_audio(first_part, second_part)

def pdf_scroll(pdf, length, **kwargs):
    width=500
    height=300
        
    cached_filename, success = cache.lookup(f'pdf composite {pdf}', 'png')
    if not success:
        print(f"Building composite image of {pdf}...")
        page_images = pdf2image.convert_from_path(pdf, **kwargs)
        page_images = list(map(lambda x: np.array(x), page_images))

        big_image = np.vstack(page_images)
        cv2.imwrite(cached_filename, big_image)
        cache.insert(cached_filename)
    else:
        print(f"Using cached composite image of {pdf}")
        big_image = cv2.imread(cached_filename)
        

    vid = static_frame(pdf, big_image, frame_rate, length)
    vid = ken_burns(vid,
        width=width,
        height=height,
        start_top_left=(0,0),
        start_bottom_right=(vid.width(), (height/width)*vid.width()),
        end_top_left=(0,vid.height()-(height/width)*vid.width()),
        end_bottom_right=(vid.width(), vid.height())
    )
    
    return vid

class spin(Clip):
    def __init__(self, clip, total_rotations, background_color):
        self.clip = clip
        self.radius = math.ceil(math.sqrt(clip.width()**2 + clip.height()**2))
        self.radius += self.radius % 2
        length_in_seconds = clip.length() / clip.frame_rate()
        rotations_per_second = total_rotations / length_in_seconds
        rotations_per_frame = rotations_per_second / clip.frame_rate()
        self.degrees_per_frame = 360 * rotations_per_frame
        self.color = [background_color[2], background_color[1], background_color[0]]

    def __repr__(self):
        return f'spin({self.clip}, {self.degrees_per_frame}, {self.color})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def frame_signature(self, index):
        sig = self.clip.frame_signature(index)
        degrees = self.degrees_per_frame * index
        return f'{sig} rotated by {degrees}'

    def get_audio(self):
        return self.clip.get_audio()
    
    def height(self):
        return self.radius

    def width(self):
        return self.radius

    def length(self):
        return self.clip.length()

    def get_frame(self, index):
        frame = np.zeros([self.radius, self.radius, 3], np.uint8)
        frame[:] = self.color

        original_frame = self.clip.get_frame(index)

        a = (frame.shape[0] - original_frame.shape[0])
        b = (frame.shape[1] - original_frame.shape[1])
        
        frame[
            int(a/2):int(a/2)+original_frame.shape[0],
            int(b/2):int(b/2)+original_frame.shape[1],
            :
        ] = original_frame

        degrees = self.degrees_per_frame * index

        # https://stackoverflow.com/questions/9041681/opencv-python-rotate-image-by-x-degrees-around-specific-point
        image_center = tuple(np.array(frame.shape[1::-1]) / 2)
        rot_mat = cv2.getRotationMatrix2D(image_center, degrees, 1.0)
        rotated_frame = cv2.warpAffine(frame, rot_mat, frame.shape[1::-1], flags=cv2.INTER_LINEAR, borderValue=self.color)
        return rotated_frame
        

class super_superimpose(Clip):
    def __init__(self, under_clip, over_clip, x, y, start_frame, audio='ignore'):
        if isinstance(x, int):
            def func(index, x=x):
                return x
            x = func
        if isinstance(y, int):
            def func(index, y=y):
                return y
            y = func

        assert callable(x), f'x should be either int or callable, got {type(x)}'
        assert callable(y), f'y should be either int or callable, got {type(y)}'

        assert isinstance(start_frame, int)

        self.under_clip = under_clip
        self.over_clip = over_clip
        self.x = x
        self.y = y
        self.start_frame = start_frame


    def get_frame(self, index):
        frame = np.copy(self.under_clip.get_frame(index))
        if index >= self.start_frame and index - self.start_frame < self.over_clip.length():
            over_frame = self.over_clip.get_frame(index - self.start_frame)

            x = self.x(index)
            y = self.y(index)
            x0 = x
            x1 = x + over_frame.shape[1]
            y0 = y
            y1 = y + over_frame.shape[0]

            #print()
            #print(f'before: index={index} x0={x0} x1={x1} y0={y0} y1={y1} frame.shape={frame.shape} over_frame.shape={over_frame.shape}')
            if x1 >= 0 and x0 <= frame.shape[1] and y1 >= 0 and y0 <= frame.shape[0]:
                if x0 < 0:
                    over_frame = over_frame[:,-x0:,:]
                    x0 = 0
                if x1 >= frame.shape[1]:
                    over_frame = over_frame[:,0:frame.shape[1]-x0,:]
                    x1 = frame.shape[1]

                if y0 < 0:
                    over_frame = over_frame[-y0:,:,:]
                    y0 = 0
                if y1 >= frame.shape[0]:
                    over_frame = over_frame[0:frame.shape[0]-y0,:,:]
                    y1 = frame.shape[0]

                #print(f'after:  index={index} x0={x0} x1={x1} y0={y0} y1={y1} frame.shape={frame.shape} over_frame.shape={over_frame.shape}')
                frame[y0:y1, x0:x1, :] = over_frame
            # else:
            #     print("Off screen")

        return frame


def hold_at_end(clip, target_length):
    return chain(
        clip, repeat_frame(clip, clip.length()-1,
        target_length-clip.length())
    )


def spq(self, filename="spq.mp4"):
    self.save(filename)
    os.system("mplayer " + filename)
    sys.exit(0)
Clip.save_play_quit = spq
Clip.spq = spq
