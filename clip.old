from zipfile import ZipFile
import glob
import hashlib
import io

from PIL import Image, ImageFont, ImageDraw
import pdf2image
import scipy.signal

class mix(Audio):
    """
    Add together a series of audio clips, sample by sample.    The sample rates
    and number of channels must match.    The resulting length will match the
    longest of the input clips.
    """

    def __init__(self, *args):
        # Construct our list of audios.
        self.audios = list()
        for x in args:
            if isiterable(x):
                self.audios += x
            else:
                self.audios.append(x)

        # Sanity checks.
        for audio in self.audios: assert isinstance(audio, Audio)
        assert len(self.audios) > 0, "Need at least one audio to mix."
        assert len(set(map(lambda x: x.sample_rate(), self.audios))) == 1, "Cannot chain audios because the sample rates do not match." + str(list(map(lambda x: x.sample_rate(), self.audios)))
        assert len(set(map(lambda x: x.sample_rate(), self.audios))) == 1, "Cannot chain audios because the numbers of channels do not match." + str(list(map(lambda x: x.num_channels(), self.audios)))

    def __repr__(self):
        return f'mix({self.audios})'

    def sample_rate(self):
        return self.audios[0].sample_rate()

    def num_channels(self):
        return self.audios[0].num_channels()

    def length(self):
        return max(map(lambda x: x.length(), self.audios))

    def compute_samples(self):
        r = np.zeros((self.length(), self.num_channels()))
        for audio in self.audios:
            r[:audio.length()] += audio.get_samples()
        return r

class mix_at(Audio):
    """
    Add together a series of audio clips, sample by sample, each starting at
    given sample.    Arguments should be (audio, start) tuples.    The sample rates
    and number of channels must match.
    """

    def __init__(self, *args):
        for tup in args:
            assert isinstance(tup, tuple)
            audio, start = tup
            assert isinstance(audio, Audio)
            assert isinstance(start, int)

        self.tups = args

        assert len(self.tups) > 0, "Need at least one audio to mix."
        assert len(set(map(lambda x: x[0].sample_rate(), self.tups))) == 1, "Cannot mix audios because the sample rates do not match." + str(list(map(lambda x: x[0].sample_rate(), self.tups)))
        assert len(set(map(lambda x: x[0].sample_rate(), self.tups))) == 1, "Cannot mix audios because the numbers of channels do not match." + str(list(map(lambda x: x.num_channels(), self.tups)))

    def __repr__(self):
        return f'mix_at({self.tups})'

    def sample_rate(self):
        return self.tups[0][0].sample_rate()

    def num_channels(self):
        return self.tups[0][0].num_channels()

    def length(self):
        return max(map(lambda x: x[0].length() + x[1], self.tups))

    def compute_samples(self):
        r = np.zeros((self.length(), self.num_channels()))
        for audio, start in self.tups:
            r[start:start+audio.length()] += audio.get_samples()
        return r

class volume(Audio):
    """
    Scale the volume of an audio clip, sample by sample.
    """

    def __init__(self, audio, factor):
        assert isinstance(audio, Audio)
        assert isfloat(factor)
        self.audio = audio
        self.factor = factor

    def __repr__(self):
        return f'volume({self.audio}, factor)'

    def sample_rate(self):
        return self.audio.sample_rate()

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.audio.length()

    def compute_samples(self):
        return self.factor * self.audio.get_samples()

class resample(Audio):
    """
    Change both the sample rate of an audio clip and its length, using some sort
    of fancy resampling algorithm.
    """

    def __init__(self, audio, new_sample_rate, new_length):
        assert isinstance(audio, Audio)
        assert isfloat(new_sample_rate)
        assert isinstance(new_length, int)
        self.audio = audio
        self.new_sample_rate = new_sample_rate
        self.new_length = new_length

    def __repr__(self):
        return f'resample({self.audio}, {self.new_sample_rate}, {self.new_length})'

    def sample_rate(self):
        return self.new_sample_rate

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.new_length

    def compute_samples(self):
        data = self.audio.get_samples()
        x = scipy.signal.resample(data, self.new_length)
        return x

def change_sample_rate(audio, new_sample_rate):
    return resample(audio, new_sample_rate, round(audio.length() * new_sample_rate/audio.sample_rate()))

def timewarp_audio(audio, factor):
    return resample(audio, audio.sample_rate(), int(audio.length()*factor))

def force_audio_length(audio, target_length):
    """Return an audio clip with exactly the given length.    Trim the end or add silence to achieve this."""
    if audio.length() < target_length:
        return chain_audio(audio, silence(target_length-audio.length(), audio.sample_rate(), audio.num_channels()))
    elif audio.length() > target_length:
        return slice_audio(audio, 0, target_length)
    else:
        return audio


class fade_audio(Audio):
    """Fade between two sounds, which must be equal in length, sample rate, and number of channels."""

    def __init__(self, audio1, audio2):
        assert isinstance(audio1, Audio)
        assert isinstance(audio2, Audio)
        assert audio1.sample_rate() == audio2.sample_rate(), "Mismatched sample rates %d and %d" % (audio1.sample_rate(), audio2.sample_rate())
        assert audio1.num_channels() == audio2.num_channels()
        assert audio1.length() == audio2.length(), f'Cannot fade audio because the lengths do not match. {audio1.length()} != {audio2.length()}'

        self.audio1 = audio1
        self.audio2 = audio2

    def __repr__(self):
        return 'fade_audio(%s, %s)' % (self.audio1.__repr__(), self.audio2.__repr__())

    def sample_rate(self):
        return self.audio1.sample_rate()

    def num_channels(self):
        return self.audio1.num_channels()

    def length(self):
        return self.audio1.length()

    def compute_samples(self):
        if self.length() > 1e8:
            print("Starting fade_audio.compute_samples on a long segment.    Hold onto your hat.")
        a1 = self.audio1.get_samples()
        a2 = self.audio1.get_samples()
        data = (
            np.linspace([1.0]*self.num_channels(), [0.0]*self.num_channels(), self.length()) * a1
            +
            np.linspace([0.0]*self.num_channels(), [1.0]*self.num_channels(), self.length()) * a2
        )
        return data

        # It's amazing how slow the naive version is...
        # a1 = self.audio1.get_samples()
        # a2 = self.audio2.get_samples()
        # r = np.zeros((self.length(), self.num_channels()))
        # for index in range(0, self.length()):
        #     a = self.alpha(index)
        #     r[index] = (1-a)*a1[index] + a*a2[index]
        # return r

class reverse_audio(Audio):
    """Same sound, played backward."""

    def __init__(self, audio):
        assert isinstance(audio, Audio)
        self.audio = audio

    def __repr__(self):
        return 'reverse_audio(%s)' % (self.audio.__repr__())

    def sample_rate(self):
        return self.audio.sample_rate()

    def num_channels(self):
        return self.audio.num_channels()

    def length(self):
        return self.audio.length()

    def compute_samples(self):
        return np.flip(self.audio.get_samples(), axis=0)


if sys.version_info.major == 3 and sys.version_info.minor < 8:
    Label = collections.namedtuple('Label', ['text', 'color', 'font', 'size', 'x', 'y', 'start', 'end'])
else:
    Label = collections.namedtuple('Label', ['text', 'color', 'font', 'size', 'x', 'y', 'start', 'end'], defaults=[None]*4)


def get_font(font, size):
    """
    Return a TrueType font for use on Pillow images, with caching to prevent
    loading the same font again and again.    (The performance improvement seems to
    be small but non-zero.)
    """
    if (font, size) not in get_font.cache:
        try:
            get_font.cache[(font, size)] = ImageFont.truetype(font, size)
        except OSError:
            raise Exception(f"Failed to open font {font}.")
    return get_font.cache[(font, size)]
get_font.cache = dict()

class add_labels(Clip):
    """
    Superimpose one or more text labels onto every frame of a clip.
    """

    def __init__(self, clip, labels):
        assert isinstance(clip, Clip)
        assert isiterable(labels)

        # If we just got one label, pretend it was a list.
        if isinstance(labels, Label):
            labels = [labels]

        for (i, label) in enumerate(labels):
            assert isinstance(label, Label)
            assert isfloat(label.size)
            assert isinstance(label.font, str)
            assert isinstance(label.text, str)
            assert isinstance(label.x, int), f'Got {type(label.x)} instead of int for label x.'
            assert isinstance(label.y, int)
            assert iscolor(label.color)

            if label.start is None:
                labels[i] = label._replace(start=0)
                label = labels[i]

            if label.end is None:
                labels[i] = label._replace(end=clip.length())
                label = labels[i]

            assert isinstance(label.start, int), f"Label start frame should be an integer, not {label.start}."
            assert isinstance(label.end, int)

        self.clip = clip
        self.labels = labels

    def __repr__(self):
        return 'add_labels(%s, %s)' % (self.clip.__repr__(), self.labels)

    def frame_rate(self):
        return self.clip.frame_rate()
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.clip.length()
    def frame_signature(self, index):
        return self.clip.frame_signature(index) + "+" + ",".join(map(lambda x: f'"{x.text}" {x.color} {x.font} {x.size} {x.x} {x.y}', filter(lambda x: x.start <= index and index < x.end, self.labels)))

    def get_frame(self, index):
        frame = self.clip.get_frame(index)
        pil_image = Image.fromarray(frame)
        draw = ImageDraw.Draw(pil_image)

        for label in self.labels:
            if label.start <= index and index < label.end:
                font = get_font(label.font, label.size)
                draw.text((label.x, label.y), label.text, font=font, fill=(label.color[2],label.color[1],label.color[0]))

        array = np.array(pil_image)
        return array

    def get_audio(self):
        return self.clip.get_audio()

def add_titles(clip, labels, x=None, y=None, halign="center", valign="center", lalign="center", spacing=1.2):
    """
    Add several labels, with the locations computed to stack nicely. The
    labels parameter should be an iterable of Labels, whose positions are
    ignored.
    """

    # If we just got one label, pretend it was a list.
    if isinstance(labels, Label):
        labels = [labels]

    # Make a dummy frame, so we can compute text sizes.
    pil_image = Image.new("RGB", (clip.width(), clip.height()))
    draw = ImageDraw.Draw(pil_image)

    # Figure out how big the rectangle containing the titles needs to be.
    width = 0
    height = 0
    for label in labels:
        font = get_font(label.font, label.size)
        size = draw.textsize(label.text, font=font)
        width = max(width, size[0])
        height += int(spacing * size[1])

    # If we didn't get an x or y position, use the center of the frame.
    if x is None:
        x = int(clip.width()/2)
    if y is None:
        y = int(clip.height()/2)

    # Figure out where the top left corner of the box should be placed.
    if halign == 'left':
        left = x
    elif halign == 'right':
        left = x - width
    elif halign == 'center':
        left = x - int(width/2)
    else:
        raise Exception(f'Unknown halign {halign}.')

    if valign == 'top':
        top = y
    elif valign == 'bottom':
        top = y - height
    elif valign == 'center':
        top = y - int(height/2)
    else:
        raise Exception(f'Unknown valign {valign}.')

    # Create labels positioned correctly within that box.
    new_labels = list()
    y = top
    for label in labels:
        font = get_font(label.font, label.size)
        size = draw.textsize(label.text, font=font)

        if lalign == 'left':
            x = left
        elif lalign == 'right':
            x = left + width - size[0]
        elif lalign == 'center':
            x = left + int((width - size[0])/2)
        else:
            raise Exception(f'Unknown lalign {lalign}.')

        new_label = label._replace(x=x, y=y)
        new_labels.append(new_label)
        y += int(spacing * size[1])

    # Return an add_labels that uses these correctly-positioned new labels.
    return add_labels(clip, new_labels)

class fade(Clip):
    """Fade between two clips, which must be equal in length, frame size, frame rate, sample rate, and number of channels."""
    def __init__(self, clip1, clip2):
        assert isinstance(clip1, Clip)
        assert isinstance(clip2, Clip)
        assert clip1.frame_rate() == clip2.frame_rate(), "Mismatched frame rates %d and %d" % (clip1.frame_rate(), clip2.frame_rate())
        assert clip1.width() == clip2.width(), f'Mismatched widths {clip1.width()} and {clip2.width()}.'
        assert clip1.height() == clip2.height()
        assert clip1.length() == clip2.length()
        assert clip1.get_audio().sample_rate() == clip2.get_audio().sample_rate(), f'Cannot fade between audio with sample rate {clip1.get_audio().sample_rate()} and audio with sample rate {clip2.get_audio().sample_rate()}.'

        assert clip1.get_audio().num_channels() == clip2.get_audio().num_channels(), f'Cannot fade between audio with {clip1.get_audio().num_channels()} channel(s) and audio with {clip2.get_audio().num_channels()} channel(s).'

        assert clip1.get_audio().length() == clip2.get_audio().length(), f'Cannot fade between clips because their audio lengths do not match. {clip1.get_audio().length()} != {clip2.get_audio().length()}'

        self.clip1 = clip1
        self.clip2 = clip2

    def __repr__(self):
        return f'fade({self.clip1}, {self.clip2})'

    def frame_rate(self):
        return self.clip1.frame_rate()

    def width(self):
        return self.clip1.width()

    def height(self):
        return self.clip1.height()

    def length(self):
        return self.clip1.length()

    def alpha(self, index):
        return (self.clip1.length()-1 - index)/(self.clip1.length())

    def frame_signature(self, index):
        a = self.alpha(index)
        return "(%f%s + %f%s)" % (a, self.clip1.frame_signature(index), 1-a, self.clip2.frame_signature(index))

    def get_frame(self, index):
        a = self.alpha(index)
        return cv2.addWeighted(
            self.clip1.get_frame(index), a,
            self.clip2.get_frame(index), 1.0-a,
            0
        )

    def get_audio(self):
        return fade_audio(self.clip1.get_audio(), self.clip2.get_audio())


def slice_out(clip, start, end):
    return chain(slice(clip, 0, start), slice(clip, end, clip.length()))

class superimpose(Clip):
    """Superimpose one clip on another, at a given place in each frame, starting
    at a given time."""

    def __init__(self, under_clip, over_clip, x, y, start_frame, audio='ignore'):
        assert isinstance(under_clip, Clip)
        assert isinstance(over_clip, Clip)
        assert isinstance(x, int)
        assert x >= 0
        assert isinstance(y, int)
        assert y >= 0
        assert isfloat(start_frame)
        assert start_frame >= 0
        start_frame = int(start_frame)

        assert y + over_clip.height() <= under_clip.height(), f"Superimposing {over_clip} onto {under_clip} at ({x}, {x}), but the under clip is not tall enough.    It would need to be {y+over_clip.height()}, but is only {under_clip.height()}."
        assert x + over_clip.width() <= under_clip.width(), "Superimposing %s onto %s at (%d, %d), but the under clip is not wide enough." % (over_clip.signature(), under_clip.signature(), x, y)
        assert start_frame + over_clip.length() <= under_clip.length(), f"Superimposing {over_clip} onto {under_clip} at frame {start_frame}, but the under clip is not long enough."
        assert under_clip.frame_rate() == over_clip.frame_rate(), f'Superimposing {over_clip} onto {under_clip} at frame {start_frame}, but the framerates do not match ({over_clip.frame_rate()} != {under_clip.frame_rate()}.'

        self.under_clip = under_clip
        self.over_clip = over_clip
        self.x = x
        self.y = y
        self.start_frame = start_frame

        if audio == 'ignore':
            self.audio = under_clip.get_audio()
        elif audio in ['replace', 'mix']:
            original_audio = under_clip.get_audio()
            new_audio = over_clip.get_audio()
            assert original_audio.sample_rate() == new_audio.sample_rate()
            assert original_audio.num_channels() == new_audio.num_channels()

            start_sample = under_clip.frame_to_sample(start_frame)
            end_sample = under_clip.frame_to_sample(start_frame + over_clip.length())

            before = slice_audio(original_audio, 0, start_sample)
            during = slice_audio(original_audio, start_sample, end_sample)
            after = slice_audio(original_audio, end_sample, original_audio.length())

            if audio == 'replace':
                self.audio = chain_audio(before, new_audio, after)
            else: # mix
                self.audio = chain_audio(before, mix(during, new_audio), after)
        else:
            raise Exception(f'Unknown audio mode {self.audio} in superimpose.')

    def __repr__(self):
        return f'superimpose({self.under_clip}, {self.over_clip}, {self.x}, {self.y}, {self.start_frame}, audio={self.audio})'

    def frame_rate(self):
        return self.under_clip.frame_rate()

    def width(self):
        return self.under_clip.width()

    def height(self):
        return self.under_clip.height()

    def length(self):
        return self.under_clip.length()

    def frame_signature(self, index):
        if index >= self.start_frame and index - self.start_frame < self.over_clip.length():
            return "%s+(%s@(%d,%d,%d))" % (self.under_clip.frame_signature(index), self.over_clip.frame_signature(index - self.start_frame), self.x, self.y, self.start_frame)
        return self.under_clip.frame_signature(index)

    def get_frame(self, index):
        frame = np.copy(self.under_clip.get_frame(index))
        if index >= self.start_frame and index - self.start_frame < self.over_clip.length():
            x0 = self.x
            x1 = self.x + self.over_clip.width()
            y0 = self.y
            y1 = self.y + self.over_clip.height()
            frame[y0:y1, x0:x1, :] = self.over_clip.get_frame(index - self.start_frame)
        return frame

    def get_audio(self):
        return self.audio

def superimpose_center(under_clip, over_clip, start_frame, audio='ignore'):
    """Superimpose one clip on another, in the center of each frame, starting at
    a given time."""
    assert isinstance(under_clip, Clip)
    assert isinstance(over_clip, Clip)
    assert isinstance(start_frame, int)
    x = int(under_clip.width()/2) - int(over_clip.width()/2)
    y = int(under_clip.height()/2) - int(over_clip.height()/2)
    return superimpose(under_clip, over_clip, x, y, start_frame, audio)


class filter_frames(Clip):
    """A clip formed by passing the frames of another clip through some function.
    The function should have one argument, the input frame, and return the output
    frame.    The output frames may have a different size from the input ones, but
    must all be the same size across the whole clip.    Audio remains unchanged."""

    def __init__(self, clip, func, name=None):
        assert isinstance(clip, Clip)
        assert callable(func)
        self.clip = clip
        self.func = func
        if name:
            self.func.__name__ = name
        self.sample_frame = func(clip.get_frame(0))

    def __repr__(self):
        return f'filter_frames({self.clip}, {self.func.__name__})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def length(self):
        return self.clip.length()

    def width(self):
        return self.sample_frame.shape[1]

    def height(self):
        return self.sample_frame.shape[0]

    def frame_signature(self, index):
        return "%s(%s)" % (self.func.__name__, self.clip.frame_signature(index))

    def get_frame(self, index):
        return self.func(self.clip.get_frame(index))

    def get_audio(self):
        return self.clip.get_audio()

def scale_by_factor(clip, factor):
    """Scale the frames of a clip by a given factor."""
    assert isinstance(clip, Clip)
    assert isfloat(factor)
    assert factor > 0
    new_width = int(factor * clip.width())
    new_height = int(factor * clip.height())
    return scale_to_size(clip, new_width, new_height)

def scale_to_size(clip, new_width, new_height):
    """Scale the frames of a clip to a given size, possibly distorting them."""
    assert isinstance(clip, Clip)
    assert isinstance(new_width, int), f'Width should be an integer.    Got {new_width} instead.'
    assert isinstance(new_height, int), f'Height should be an interger.    Got {new_height} instead.'
    def scale_filter(frame):
        return cv2.resize(frame, (new_width, new_height))
    scale_filter.__name__ = f'scale[{new_width}x{new_height}]'
    return filter_frames(clip, scale_filter)

def scale_to_fit(clip, max_width, max_height):
    """Scale the frames of a clip to fit within the given constraints,
    maintaining the aspect ratio."""

    aspect1 = clip.width() / clip.height()
    aspect2 = max_width / max_height

    if aspect1 > aspect2:
        # Fill width.
        new_width = max_width
        new_height = clip.height() * max_width / clip.width()
    else:
        # Fill height.
        new_height = max_height
        new_width = clip.width() * max_height / clip.height()

    return scale_to_size(clip, int(new_width), int(new_height))

def letterbox(clip, width, height):
    clip = scale_to_fit(clip, width, height)
    background = black(height, width, clip.frame_rate(), clip.length())
    a = clip.get_audio()
    background = replace_audio(background, silence(a.length(), a.sample_rate(), a.num_channels()))
    return superimpose(background, clip, int((background.width()-clip.width())/2), int((background.height()-clip.height())/2), 0, audio='replace')


class image_glob(Clip):
    """Form a video from a collection of identically-sized image files that match
    a unix-style pattern, at a given frame rate."""

    def __init__(self, pattern, frame_rate):
        self.pattern = pattern
        assert isfloat(frame_rate)
        assert frame_rate > 0

        self.frame_rate_ = frame_rate
        self.filenames = sorted(glob.glob(pattern))
        assert len(self.filenames) > 0, "No files matched pattern: " + pattern
        self.sample_frame = cv2.imread(self.filenames[0])
        assert self.sample_frame is not None

    def __repr__(self):
        return f'image_glob({self.pattern}, {self.frame_rate})'

    def frame_rate(self):
        return self.frame_rate_

    def width(self):
        return self.sample_frame.shape[1]

    def height(self):
        return self.sample_frame.shape[0]

    def length(self):
        return len(self.filenames)

    def frame_signature(self, index):
        return self.filenames[index]

    def get_frame(self, index):
        return cv2.imread(self.filenames[index])

    def get_audio(self):
        return self.default_audio()

class repeat_frame(Clip):
    """A clip that shows the same frame, from another clip, over and over."""
    def __init__(self, clip, frame_index, length):
        assert isinstance(clip, Clip)

        assert isinstance(frame_index, int)
        assert frame_index >= 0
        assert frame_index < clip.length(), "Trying to repeat frame %d of %s, but the last valid frame index is %s." % (frame_index, clip.signature(), clip.length()-1)

        assert isinstance(length, int)
        assert length > 0

        self.clip = clip
        self.frame_index = frame_index
        self.length_ = length

    def __repr__(self):
        return f'repeat_frame({self.clip}, {self.frame_index}, {self.length_})'

    def frame_rate(self):
        return self.clip.frame_rate()

    def length(self):
        return self.length_

    def width(self):
        return self.clip.width()

    def height(self):
        return self.clip.height()

    def frame_signature(self, index):
        return self.clip.frame_signature(self.frame_index)

    def get_frame(self, index):
        return self.clip.get_frame(self.frame_index)

    def get_audio(self):
        return self.default_audio()

def crop(clip, lower_left, upper_right):
    """Trim the frames of a clip to show only the rectangle between lower_left and upper_right."""
    assert isinstance(clip, Clip)

    assert isinstance(lower_left[0], int)
    assert lower_left[0] >= 0

    assert isinstance(lower_left[1], int)
    assert lower_left[1] >= 0

    assert isinstance(upper_right[0], int)
    assert upper_right[0] <= clip.width()

    assert isinstance(upper_right[1], int)
    assert upper_right[1] <= clip.height()

    assert lower_left[0] < upper_right[0]
    assert lower_left[1] < upper_right[1]

    def crop_filter(frame):
        return frame[lower_left[1]:upper_right[1], lower_left[0]:upper_right[0], :]

    return filter_frames(clip, crop_filter, name=f'crop{lower_left}{upper_right}')

class force_framerate(Clip):
    """Change the frame rate at which a clip thinks it should be played.    Audio is padded or truncated to match, and thus is likely to become out-of-sync."""
    def __init__(self, clip, frame_rate):
        assert isinstance(clip, Clip)
        assert isfloat(frame_rate)
        assert frame_rate > 0

        self.clip = clip
        self.frame_rate_ = frame_rate
        self.audio = clip.get_audio()
        target_length = self.frame_to_sample(self.length())
        self.audio = force_audio_length(self.audio, target_length)

    def __repr__(self):
        return f'force_framerate({self.clip}, {self.frame_rate_})'

    def frame_rate(self):
        return self.frame_rate_
    
    def width(self):
        return self.clip.width()
    
    def height(self):
        return self.clip.height()
    
    def length(self):
        return self.clip.length()
    
    def get_frame(self, index):
        return self.clip.get_frame(index)
    
    def frame_signature(self, index):
        return self.clip.frame_signature(index)
    
    def get_audio(self):
        return self.audio

def fade_in(clip, fade_frames, color=(0,0,0)):
    """Fade in from a solid color, defaulting to black."""
    assert isinstance(clip, Clip)
    assert isinstance(fade_frames, int)
    assert fade_frames >= 0
    assert fade_frames <= clip.length(), "Cannot fade into %s for %f frames, because the clip is only %f frames long." % (clip, fade_frames, clip.length())
    assert iscolor(color)
    blk = solid(clip.height(), clip.width(), clip.frame_rate(), fade_frames, color=color)
    return fade_chain(fade_frames, blk, clip)

def fade_out(clip, fade_frames, color=(0,0,0)):
    """Fade out to a solid color, defaulting to black."""
    assert isinstance(clip, Clip)
    assert isinstance(fade_frames, int)
    assert fade_frames >= 0
    assert fade_frames <= clip.length(), "Cannot fade out from %s for %f frames, because the clip is only %f frames long." % (clip, fade_frames, clip.length())

    blk = solid(clip.height(), clip.width(), clip.frame_rate(), fade_frames, color=color)
    return fade_chain(fade_frames, clip, blk)



class reverse(Clip):
    """Reverse the video in a clip.    No change to the audio."""
    def __init__(self, clip):
        assert isinstance(clip, Clip)
        self.clip = clip
    def __repr__(self):
        return f'reverse({self.clip})'
    def frame_rate(self):
        return self.clip.frame_rate()
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.clip.length()
    def frame_signature(self, index):
        return self.clip.frame_signature(self.clip.length() - index - 1)
    def get_frame(self, index):
        return self.clip.get_frame(self.clip.length() - index - 1)
    def get_audio(self):
        return self.clip.get_audio()


class resample_frames(Clip):
    """
    Modify the frame rate and the length of the video.    No change to the audio.
    """
    def __init__(self, clip, new_frame_rate, new_length):
        assert isinstance(clip, Clip)
        assert isfloat(new_frame_rate)
        assert isinstance(new_length, int)
        self.clip = clip
        self.new_frame_rate = new_frame_rate
        self.new_length = new_length

    def new_index(self, index):
        x = int(self.clip.length()*index/self.new_length)
        return x
    def __repr__(self):
        return f'resample_frames({self.clip}, {self.new_frame_rate}, {self.new_length})'
    def frame_rate(self):
        return self.new_frame_rate
    def width(self):
        return self.clip.width()
    def height(self):
        return self.clip.height()
    def length(self):
        return self.new_length
    def frame_signature(self, index):
        return self.clip.frame_signature(self.new_index(index))
    def get_frame(self, index):
        return self.clip.get_frame(self.new_index(index))
    def get_audio(self):
        return self.clip.get_audio()

def timewarp(clip, factor):
    assert isinstance(clip, Clip)
    assert isfloat(factor)
    assert factor > 0
    a = clip.get_audio()
    x = resample_frames(clip, clip.frame_rate(), int(clip.length()*factor))
    a = timewarp_audio(a, factor)
    x = replace_audio(x, a)
    return x

def change_framerate(clip, new_frame_rate):
    assert isinstance(clip, Clip)
    assert isfloat(new_frame_rate)
    assert new_frame_rate > 0
    new_length = int(new_frame_rate*clip.length()/clip.frame_rate())
    return resample_frames(clip, new_frame_rate, new_length)

class pdf_page(Clip):
    """A silent video constructed from a single page of a PDF."""
    def __init__(self, pdf, page_num, length, frame_rate, **kwargs):
        assert isinstance(length, int)
        assert length > 0, f'Cannot create a PDF clip with length {length}.'
        self.pdf = pdf
        self.page_num = page_num
        self.frame_rate_ = frame_rate
        self.length_ = length
        self.hash = sha256sum(self.pdf)
        self.kwargs = kwargs
        images = pdf2image.convert_from_path(self.pdf, first_page=page_num, last_page=page_num, **kwargs)
        self.the_frame = np.array(images[0])

        # The code above seems sometimes (or always?) to give an image that has the
        # red and blue channels swapped.    Fix it.
        if images[0].mode == 'RGB':
            self.the_frame = self.the_frame[:,:,::-1]
        else:
            print("Tread carefully, because I'm not sure if a PIL image from {pdf}, which has mode {images[0].mode} needs to have channels swapped.")

        # The code above seems sometimes to return an image that is not the
        # correct size, off by one in the width.    Fix it.
        if 'size' in kwargs:
            w = kwargs['size'][0]
            h = kwargs['size'][1]
            if h != self.the_frame.shape[0] or w != self.the_frame.shape[1]:
                self.the_frame = self.the_frame[0:h,0:w]

    def __repr__(self):
        return f'pdf_page({self.pdf}, {self.page_num}, {self.length_}, {self.frame_rate_}, {self.kwargs})'
    def frame_rate(self):
        return self.frame_rate_
    def width(self):
        return self.the_frame.shape[1]
    def height(self):
        return self.the_frame.shape[0]
    def length(self):
        return self.length_
    def get_audio(self):
        return self.default_audio()
    def frame_signature(self, index):
        return f'pdf_page: {self.pdf}, {self.hash[:5]}, {self.page_num}, {self.kwargs})'
    def get_frame(self, index):
        return self.the_frame


def loop(clip, length):
    "Repeat a clip as needed to fill the given length."
    assert isinstance(clip, Clip)
    assert isinstance(length, int)
    assert length > 0
    full_plays = int(length/clip.length())
    partial_play = length - full_plays*clip.length()
    return chain(full_plays*[clip], slice_video(clip, 0, partial_play))

class zip_file(Clip):
    def __init__(self, fname, frame_rate=None):
        assert isinstance(fname, str)
        assert os.path.isfile(fname), f'Trying to open {fname}, which does not exist.'
        self.fname = fname
        self.zf = ZipFile(fname, 'r')

        image_formats = ['tga']    # Many others are likely to work, but haven't been tested.
        pattern = ".(" + "|".join(image_formats) + ")$"

        self.info_list = sorted(filter(lambda x: re.search(pattern, x.filename), self.zf.infolist()), key=lambda x: x.filename)

        assert isfloat(frame_rate)
        assert frame_rate > 0
        self.frame_rate_ = frame_rate

        self.sample_frame = self.get_frame(0)

    def __repr__(self):
        return f'zip_file("{self.fname}", frame_rate={self.frame_rate_})'

    def frame_rate(self):
        return self.frame_rate_

    def width(self):
        return self.sample_frame.shape[1]

    def height(self):
        return self.sample_frame.shape[0]

    def length(self):
        return len(self.info_list)

    def frame_signature(self, index):
        return f"zip_file_member({self.fname}, {self.info_list[index].filename})"

    def get_frame(self, index):
        data = self.zf.read(self.info_list[index])
        pil_image = Image.open(io.BytesIO(data)).convert('RGB')
        frame = np.array(pil_image)
        frame = frame[:,:,::-1]
        return frame

    def get_audio(self):
        return self.default_audio()

def sha256sum(filename):
    # https://stackoverflow.com/questions/22058048/hashing-a-file-in-python
    h = hashlib.sha256()
    b = bytearray(128*1024)
    mv = memoryview(b)
    with open(filename, 'rb', buffering=0) as f:
        for n in iter(lambda: f.readinto(mv), 0):
            h.update(mv[:n])
    return h.hexdigest()


match = re.search(r'displaymatrix: rotation of -90.00 degrees', deets)
if match:
    self.width_, self.height_ = self.height_, self.width_

